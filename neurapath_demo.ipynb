{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a96e8c5e",
   "metadata": {},
   "source": [
    "# NeuraPath Demo Notebook\n",
    "## Step 1. Define the Problem\n",
    "Goal: Given a candidate’s resume (list of skills) and a target job role (aggregated from jobs in selected industries), compute:\n",
    "\n",
    "Fit Score (0–1 weighted overlap)\n",
    "\n",
    "Matched vs. Missing skill categories\n",
    "\n",
    "Optional salary context (median/min per role cluster)\n",
    "\n",
    "JSON output for the frontend\n",
    "\n",
    "Primary user story: As a job seeker, I want to see how my skills compare to a target role so I know which skills to develop next.\n",
    "This notebook runs the rapid ML prototype for Resume→Role fit scoring.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c81b3d",
   "metadata": {},
   "source": [
    "## Step 2. Select a Small Dataset\n",
    "We’ll subset from your large job tables to keep iteration fast.\n",
    "\n",
    "2A. Pick Role Clusters (editable)\n",
    "We’ll build 5 starter “roles” by filtering industries whose names contain certain keywords (case‑insensitive). Edit as needed:\n",
    "\n",
    "Role Key\tIndustry Keyword(s)\tNotes\n",
    "DATA_ANALYST\tdata, analytics\tData Infra & Analytics industries.\n",
    "ML_ENGINEER\tsoftware, data security, technology\tTech/Software heavy.\n",
    "NETWORK_ADMIN\tnetworking, telecommunications, it system\tInfra/Net focus.\n",
    "FRONTEND_DEV\tsoftware, internet, web\tFrontend / web product industries.\n",
    "IT_SUPPORT\tit system, consulting, services\tIT services / support focus.\n",
    "\n",
    "You can change these keywords or provide a list of industry IDs if you prefer.\n",
    "\n",
    "2B. Sample Size Rule\n",
    "Up to 5,000 jobs per role (or fewer if limited).\n",
    "\n",
    "Drop duplicates.\n",
    "\n",
    "Keep only job_ids that appear in job_skills.csv so we have skills to aggregate.\n",
    "\n",
    "Merge salary rows if available; will help produce “market view” per role."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3ff8f2",
   "metadata": {},
   "source": [
    "## Step 4. Build & Train Quickly\n",
    "Below: minimal working code skeleton that you can paste into a notebook (neurapath_demo.ipynb). Adjust paths if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c7a249d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tables:\n",
      "skills          shape=(35, 2)\n",
      "job_skills      shape=(213768, 2)\n",
      "industries      shape=(422, 2)\n",
      "job_industries  shape=(164808, 2)\n",
      "salaries        shape=(40785, 8)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. Point this to where your CSVs actually live -------------------------\n",
    "DATA_DIR = Path(\"data\")  # e.g., Path(r\"C:\\Users\\RAJEH\\Projects\\NeuraPath\\data\")\n",
    "\n",
    "# --- 2. Helper: load with checks --------------------------------------------\n",
    "def load_csv_checked(path: Path, fname: str, **read_kwargs) -> pd.DataFrame:\n",
    "    f = path / fname\n",
    "    if not f.is_file():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Required file missing: {f}\\n\"\n",
    "            f\"Current working directory: {Path.cwd()}\\n\"\n",
    "            f\"Files in {path}: {list(path.glob('*'))}\"\n",
    "        )\n",
    "    return pd.read_csv(f, **read_kwargs)\n",
    "\n",
    "# --- 3. Load all core tables ------------------------------------------------\n",
    "def load_core_tables(data_dir: Path):\n",
    "    # Load\n",
    "    skills = load_csv_checked(data_dir, \"skills.csv\")\n",
    "    job_skills = load_csv_checked(data_dir, \"job_skills.csv\")\n",
    "    industries = load_csv_checked(data_dir, \"industries.csv\")\n",
    "    job_industries = load_csv_checked(data_dir, \"job_industries.csv\")\n",
    "    \n",
    "    # salaries is optional; create empty if absent\n",
    "    sal_path = data_dir / \"salaries.csv\"\n",
    "    if sal_path.is_file():\n",
    "        salaries = pd.read_csv(sal_path)\n",
    "    else:\n",
    "        salaries = pd.DataFrame(columns=[\"job_id\"])  # placeholder\n",
    "    \n",
    "    # --- Clean skills.skill_name --------------------------------------------\n",
    "    # Normalize column name if needed (handles Skill, skill, etc.)\n",
    "    lower_cols = {c.lower(): c for c in skills.columns}\n",
    "    if \"skill_name\" not in lower_cols:\n",
    "        # Try to infer from similar columns:\n",
    "        for guess in (\"skill\", \"name\", \"skillname\"):\n",
    "            if guess in lower_cols:\n",
    "                skills = skills.rename(columns={lower_cols[guess]: \"skill_name\"})\n",
    "                break\n",
    "    else:\n",
    "        # just standardize capitalization\n",
    "        skills = skills.rename(columns={lower_cols[\"skill_name\"]: \"skill_name\"})\n",
    "    \n",
    "    # Ensure column exists after rename attempt\n",
    "    if \"skill_name\" not in skills.columns:\n",
    "        raise ValueError(\n",
    "            \"Could not find a skill name column in skills.csv. \"\n",
    "            \"Expected 'skill_name' (case-insensitive) or a close match.\"\n",
    "        )\n",
    "    \n",
    "    # Strip whitespace\n",
    "    skills[\"skill_name\"] = skills[\"skill_name\"].astype(str).str.strip()\n",
    "    \n",
    "    return skills, job_skills, industries, job_industries, salaries\n",
    "\n",
    "# --- 4. Call it --------------------------------------------------------------\n",
    "skills, job_skills, industries, job_industries, salaries = load_core_tables(DATA_DIR)\n",
    "\n",
    "# --- 5. Quick sanity summary -------------------------------------------------\n",
    "print(\"Loaded tables:\")\n",
    "for name, df in {\n",
    "    \"skills\": skills,\n",
    "    \"job_skills\": job_skills,\n",
    "    \"industries\": industries,\n",
    "    \"job_industries\": job_industries,\n",
    "    \"salaries\": salaries,\n",
    "}.items():\n",
    "    print(f\"{name:15s} shape={df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f85666",
   "metadata": {},
   "source": [
    "### 4A. Helper: Map industries to roles\n",
    "Edit ROLE_KEYWORDS to tune grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aa5e248",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLE_KEYWORDS = {\n",
    "    \"DATA_ANALYST\":    [\"data\", \"analytics\"],\n",
    "    \"ML_ENGINEER\":     [\"software\", \"technology\", \"security\"],\n",
    "    \"NETWORK_ADMIN\":   [\"network\", \"telecommunications\", \"it system\"],\n",
    "    \"FRONTEND_DEV\":    [\"internet\", \"software\", \"web\"],\n",
    "    \"IT_SUPPORT\":      [\"consult\", \"it services\", \"services\"]\n",
    "}\n",
    "\n",
    "# build industry → role map\n",
    "def assign_role_from_industry(industry_name: str) -> list:\n",
    "    name_l = str(industry_name).lower()\n",
    "    roles = []\n",
    "    for role, kws in ROLE_KEYWORDS.items():\n",
    "        if any(kw in name_l for kw in kws):\n",
    "            roles.append(role)\n",
    "    return roles\n",
    "\n",
    "industries[\"roles\"] = industries[\"industry_name\"].apply(assign_role_from_industry)\n",
    "\n",
    "\n",
    "ind_role = industries.explode(\"roles\").dropna(subset=[\"roles\"])\n",
    "ind_role = ind_role.rename(columns={\"roles\":\"role\"})\n",
    "job_roles = job_industries.merge(ind_role[[\"industry_id\",\"role\"]], on=\"industry_id\", how=\"inner\")\n",
    "# job_id may map to multiple roles; keep all for now\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7da819f",
   "metadata": {},
   "source": [
    "### 4B. Build per‑role skill profiles\n",
    "Aggregate skill frequency for all jobs mapped to that role, then mark “required”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5dbcbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_role_skill_profile(role, min_jobs=50, required_pct=0.30):\n",
    "    job_ids = job_roles.loc[job_roles.role == role, \"job_id\"].unique()\n",
    "    if len(job_ids) == 0:\n",
    "        return pd.DataFrame()\n",
    "    js = job_skills[job_skills.job_id.isin(job_ids)]\n",
    "    freq = js.skill_abr.value_counts().rename(\"count\").reset_index().rename(columns={\"index\":\"skill_abr\"})\n",
    "    freq[\"pct_jobs\"] = freq[\"count\"] / len(job_ids)\n",
    "    freq = freq.merge(skills, on=\"skill_abr\", how=\"left\")\n",
    "    freq[\"required\"] = freq[\"pct_jobs\"] >= required_pct\n",
    "    freq[\"role\"] = role\n",
    "    return freq.sort_values(\"pct_jobs\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "role_profiles = {r: build_role_skill_profile(r) for r in ROLE_KEYWORDS}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d7d3c9",
   "metadata": {},
   "source": [
    "### 4C. Resume skill extraction (keyword match prototype)\n",
    "Provide a simple dictionary; expand with synonyms from real resumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1268caa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build regex per skill category from its name (very rough prototype)\n",
    "skills[\"pattern\"] = skills[\"skill_name\"].str.lower().str.replace(r\"[^a-z0-9]+\", \"|\", regex=True)\n",
    "\n",
    "def extract_resume_skills(resume_text: str):\n",
    "    text = resume_text.lower()\n",
    "    found = set()\n",
    "    for _, row in skills.iterrows():\n",
    "        pat = row.pattern\n",
    "        if not pat or pat == \"|\":\n",
    "            continue\n",
    "        if re.search(r\"\\b(\" + pat + r\")\\b\", text):\n",
    "            found.add(row.skill_abr)\n",
    "    return found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b2b12c",
   "metadata": {},
   "source": [
    "## Step 5. Evaluate with Simple Metrics\n",
    "Given we lack gold labels, we bootstrap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5c918e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_score(resume_skills, role_profile, required_weight=2.0):\n",
    "    req = set(role_profile.loc[role_profile.required, \"skill_abr\"])\n",
    "    opt = set(role_profile.loc[~role_profile.required, \"skill_abr\"])\n",
    "    score = 0\n",
    "    denom = required_weight*len(req) + len(opt)\n",
    "    for s in resume_skills:\n",
    "        if s in req:\n",
    "            score += required_weight\n",
    "        elif s in opt:\n",
    "            score += 1\n",
    "    return score / denom if denom else 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7573e827",
   "metadata": {},
   "source": [
    "Quick Diagnostic Metrics (no labels yet):\n",
    "\n",
    "Coverage % = len(resume_skills ∩ role_skills) / len(role_skills)\n",
    "\n",
    "Required coverage % = same but using required only\n",
    "\n",
    "Compare multiple resumes; rank roles; check if top role matches user intent\n",
    "\n",
    "If you can hand‑tag 10 resume→role pairs, compute Precision/Recall & confusion matrix for the logistic model later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7fbaff",
   "metadata": {},
   "source": [
    "## Step 6. Visualize & Present Results\n",
    "Minimal, readable visualizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ea3972a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rajeh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (3.10.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\rajeh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (2.2.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rajeh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rajeh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rajeh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\rajeh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\rajeh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rajeh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\rajeh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rajeh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rajeh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rajeh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rajeh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rajeh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_gap(resume_skills, role_profile, top_n=15):\n",
    "    df = role_profile.copy()\n",
    "    df[\"in_resume\"] = df[\"skill_abr\"].isin(resume_skills)\n",
    "    df[\"missing\"] = ~df[\"in_resume\"]\n",
    "    df = df.sort_values([\"required\",\"pct_jobs\"], ascending=[False,False]).head(top_n)\n",
    "    colors = df[\"in_resume\"].map({True:\"green\", False:\"red\"})\n",
    "    plt.barh(df[\"skill_name\"], df[\"pct_jobs\"], color=colors)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel(\"% of jobs requiring skill\")\n",
    "    plt.title(f\"Resume vs Role: {df['role'].iloc[0]}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92b77330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fit_report(resume_id, resume_text, role):\n",
    "    rskills = extract_resume_skills(resume_text)\n",
    "    prof = role_profiles[role]\n",
    "    score = fit_score(rskills, prof)\n",
    "    matched  = prof.loc[prof.skill_abr.isin(rskills), \"skill_name\"].tolist()\n",
    "    missing  = prof.loc[~prof.skill_abr.isin(rskills) & prof.required, \"skill_name\"].tolist()\n",
    "    return {\n",
    "        \"resume_id\": resume_id,\n",
    "        \"role\": role,\n",
    "        \"fit_score\": round(score, 2),\n",
    "        \"matched_skills\": matched,\n",
    "        \"missing_skills\": missing,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7569ab",
   "metadata": {},
   "source": [
    "## Step 7. Get Feedback & Iterate\n",
    "Iteration loop:\n",
    "\n",
    "Demo to team: do the required skill lists make sense?\n",
    "\n",
    "Adjust industry keywords → role definitions.\n",
    "\n",
    "Add manual synonym table per skill.\n",
    "\n",
    "Collect 5 real resumes; check which skills are missed → improve regex."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
