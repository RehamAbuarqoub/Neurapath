{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a96e8c5e",
   "metadata": {},
   "source": [
    "# NeuraPath Demo Notebook\n",
    "## Step 1. Define the Problem\n",
    "Goal: Given a candidate’s resume (list of skills) and a target job role (aggregated from jobs in selected industries), compute:\n",
    "\n",
    "Fit Score (0–1 weighted overlap)\n",
    "\n",
    "Matched vs. Missing skill categories\n",
    "\n",
    "Optional salary context (median/min per role cluster)\n",
    "\n",
    "JSON output for the frontend\n",
    "\n",
    "Primary user story: As a job seeker, I want to see how my skills compare to a target role so I know which skills to develop next.\n",
    "This notebook runs the rapid ML prototype for Resume→Role fit scoring.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c81b3d",
   "metadata": {},
   "source": [
    "## Step 2. Select a Small Dataset\n",
    "We’ll subset from your large job tables to keep iteration fast.\n",
    "\n",
    "2A. Pick Role Clusters (editable)\n",
    "We’ll build 5 starter “roles” by filtering industries whose names contain certain keywords (case‑insensitive). Edit as needed:\n",
    "\n",
    "Role Key\tIndustry Keyword(s)\tNotes\n",
    "DATA_ANALYST\tdata, analytics\tData Infra & Analytics industries.\n",
    "ML_ENGINEER\tsoftware, data security, technology\tTech/Software heavy.\n",
    "NETWORK_ADMIN\tnetworking, telecommunications, it system\tInfra/Net focus.\n",
    "FRONTEND_DEV\tsoftware, internet, web\tFrontend / web product industries.\n",
    "IT_SUPPORT\tit system, consulting, services\tIT services / support focus.\n",
    "\n",
    "You can change these keywords or provide a list of industry IDs if you prefer.\n",
    "\n",
    "2B. Sample Size Rule\n",
    "Up to 5,000 jobs per role (or fewer if limited).\n",
    "\n",
    "Drop duplicates.\n",
    "\n",
    "Keep only job_ids that appear in job_skills.csv so we have skills to aggregate.\n",
    "\n",
    "Merge salary rows if available; will help produce “market view” per role."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3ff8f2",
   "metadata": {},
   "source": [
    "## Step 4. Build & Train Quickly\n",
    "Below: minimal working code skeleton that you can paste into a notebook (neurapath_demo.ipynb). Adjust paths if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7a249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "DATA_DIR = Path(\"/mnt/data\")\n",
    "\n",
    "# --- Load core tables ---\n",
    "skills         = pd.read_csv(DATA_DIR / \"skills.csv\").assign(skill_name=lambda d: d.skill_name.str.strip())\n",
    "job_skills     = pd.read_csv(DATA_DIR / \"job_skills.csv\")          # job_id, skill_abr\n",
    "industries     = pd.read_csv(DATA_DIR / \"industries.csv\")          # industry_id, industry_name\n",
    "job_industries = pd.read_csv(DATA_DIR / \"job_industries.csv\")      # job_id, industry_id\n",
    "salaries       = pd.read_csv(DATA_DIR / \"salaries.csv\")            # job_id, salary fields (optional)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f85666",
   "metadata": {},
   "source": [
    "### 4A. Helper: Map industries to roles\n",
    "Edit ROLE_KEYWORDS to tune grouping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa5e248",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLE_KEYWORDS = {\n",
    "    \"DATA_ANALYST\":    [\"data\", \"analytics\"],\n",
    "    \"ML_ENGINEER\":     [\"software\", \"technology\", \"security\"],\n",
    "    \"NETWORK_ADMIN\":   [\"network\", \"telecommunications\", \"it system\"],\n",
    "    \"FRONTEND_DEV\":    [\"internet\", \"software\", \"web\"],\n",
    "    \"IT_SUPPORT\":      [\"consult\", \"it services\", \"services\"]\n",
    "}\n",
    "\n",
    "# build industry → role map\n",
    "def assign_role_from_industry(industry_name: str) -> list:\n",
    "    name_l = str(industry_name).lower()\n",
    "    roles = []\n",
    "    for role, kws in ROLE_KEYWORDS.items():\n",
    "        if any(kw in name_l for kw in kws):\n",
    "            roles.append(role)\n",
    "    return roles\n",
    "\n",
    "industries[\"roles\"] = industries[\"industry_name\"].apply(assign_role_from_industry)\n",
    "\n",
    "\n",
    "ind_role = industries.explode(\"roles\").dropna(subset=[\"roles\"])\n",
    "ind_role = ind_role.rename(columns={\"roles\":\"role\"})\n",
    "job_roles = job_industries.merge(ind_role[[\"industry_id\",\"role\"]], on=\"industry_id\", how=\"inner\")\n",
    "# job_id may map to multiple roles; keep all for now\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7da819f",
   "metadata": {},
   "source": [
    "### 4B. Build per‑role skill profiles\n",
    "Aggregate skill frequency for all jobs mapped to that role, then mark “required”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dbcbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_role_skill_profile(role, min_jobs=50, required_pct=0.30):\n",
    "    job_ids = job_roles.loc[job_roles.role == role, \"job_id\"].unique()\n",
    "    if len(job_ids) == 0:\n",
    "        return pd.DataFrame()\n",
    "    js = job_skills[job_skills.job_id.isin(job_ids)]\n",
    "    freq = js.skill_abr.value_counts().rename(\"count\").reset_index().rename(columns={\"index\":\"skill_abr\"})\n",
    "    freq[\"pct_jobs\"] = freq[\"count\"] / len(job_ids)\n",
    "    freq = freq.merge(skills, on=\"skill_abr\", how=\"left\")\n",
    "    freq[\"required\"] = freq[\"pct_jobs\"] >= required_pct\n",
    "    freq[\"role\"] = role\n",
    "    return freq.sort_values(\"pct_jobs\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "role_profiles = {r: build_role_skill_profile(r) for r in ROLE_KEYWORDS}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d7d3c9",
   "metadata": {},
   "source": [
    "### 4C. Resume skill extraction (keyword match prototype)\n",
    "Provide a simple dictionary; expand with synonyms from real resumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1268caa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build regex per skill category from its name (very rough prototype)\n",
    "skills[\"pattern\"] = skills[\"skill_name\"].str.lower().str.replace(r\"[^a-z0-9]+\", \"|\", regex=True)\n",
    "\n",
    "def extract_resume_skills(resume_text: str):\n",
    "    text = resume_text.lower()\n",
    "    found = set()\n",
    "    for _, row in skills.iterrows():\n",
    "        pat = row.pattern\n",
    "        if not pat or pat == \"|\":\n",
    "            continue\n",
    "        if re.search(r\"\\b(\" + pat + r\")\\b\", text):\n",
    "            found.add(row.skill_abr)\n",
    "    return found\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b2b12c",
   "metadata": {},
   "source": [
    "## Step 5. Evaluate with Simple Metrics\n",
    "Given we lack gold labels, we bootstrap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c918e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_score(resume_skills, role_profile, required_weight=2.0):\n",
    "    req = set(role_profile.loc[role_profile.required, \"skill_abr\"])\n",
    "    opt = set(role_profile.loc[~role_profile.required, \"skill_abr\"])\n",
    "    score = 0\n",
    "    denom = required_weight*len(req) + len(opt)\n",
    "    for s in resume_skills:\n",
    "        if s in req:\n",
    "            score += required_weight\n",
    "        elif s in opt:\n",
    "            score += 1\n",
    "    return score / denom if denom else 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7573e827",
   "metadata": {},
   "source": [
    "Quick Diagnostic Metrics (no labels yet):\n",
    "\n",
    "Coverage % = len(resume_skills ∩ role_skills) / len(role_skills)\n",
    "\n",
    "Required coverage % = same but using required only\n",
    "\n",
    "Compare multiple resumes; rank roles; check if top role matches user intent\n",
    "\n",
    "If you can hand‑tag 10 resume→role pairs, compute Precision/Recall & confusion matrix for the logistic model later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7fbaff",
   "metadata": {},
   "source": [
    "## Step 6. Visualize & Present Results\n",
    "Minimal, readable visualizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea3972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_gap(resume_skills, role_profile, top_n=15):\n",
    "    df = role_profile.copy()\n",
    "    df[\"in_resume\"] = df[\"skill_abr\"].isin(resume_skills)\n",
    "    df[\"missing\"] = ~df[\"in_resume\"]\n",
    "    df = df.sort_values([\"required\",\"pct_jobs\"], ascending=[False,False]).head(top_n)\n",
    "    colors = df[\"in_resume\"].map({True:\"green\", False:\"red\"})\n",
    "    plt.barh(df[\"skill_name\"], df[\"pct_jobs\"], color=colors)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel(\"% of jobs requiring skill\")\n",
    "    plt.title(f\"Resume vs Role: {df['role'].iloc[0]}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b77330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fit_report(resume_id, resume_text, role):\n",
    "    rskills = extract_resume_skills(resume_text)\n",
    "    prof = role_profiles[role]\n",
    "    score = fit_score(rskills, prof)\n",
    "    matched  = prof.loc[prof.skill_abr.isin(rskills), \"skill_name\"].tolist()\n",
    "    missing  = prof.loc[~prof.skill_abr.isin(rskills) & prof.required, \"skill_name\"].tolist()\n",
    "    return {\n",
    "        \"resume_id\": resume_id,\n",
    "        \"role\": role,\n",
    "        \"fit_score\": round(score, 2),\n",
    "        \"matched_skills\": matched,\n",
    "        \"missing_skills\": missing,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7569ab",
   "metadata": {},
   "source": [
    "## Step 7. Get Feedback & Iterate\n",
    "Iteration loop:\n",
    "\n",
    "Demo to team: do the required skill lists make sense?\n",
    "\n",
    "Adjust industry keywords → role definitions.\n",
    "\n",
    "Add manual synonym table per skill.\n",
    "\n",
    "Collect 5 real resumes; check which skills are missed → improve regex."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5be7181",
   "metadata": {},
   "source": [
    "## Quick End‑to‑End Demo (Sample Use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65048160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example resume snippet (replace with your text)\n",
    "resume_txt = \"\"\"\n",
    "Data analysis with SQL, Power BI dashboards, Python (pandas, scikit-learn),\n",
    "report automation, stakeholder reporting, Excel financial modeling, basic cloud (Azure).\n",
    "\"\"\"\n",
    "\n",
    "# Try all roles and rank\n",
    "reports = []\n",
    "for role, prof in role_profiles.items():\n",
    "    if prof.empty:\n",
    "        continue\n",
    "    rep = build_fit_report(\"r001\", resume_txt, role)\n",
    "    reports.append(rep)\n",
    "\n",
    "pd.DataFrame(reports).sort_values(\"fit_score\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e596c4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_role = max(reports, key=lambda r: r[\"fit_score\"])[\"role\"]\n",
    "plot_gap(extract_resume_skills(resume_txt), role_profiles[best_role])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
